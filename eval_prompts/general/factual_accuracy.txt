You are evaluating factual accuracy and hallucination.

## Input Data (Ground Truth):
{input}

## AI's Output:
{output}

## Checklist - Score each item (0 or 1):

1. **No Fabrication**: Did the AI avoid making up information not in the input?
2. **No Distortion**: Did the AI avoid distorting/misrepresenting input data?
3. **Accurate Extraction**: Are extracted facts accurate to the source?
4. **Reasonable Inference**: Are any inferences logically sound?
5. **No Hallucinated Details**: Are there no hallucinated names, numbers, or specifics?

## Response Format (JSON):
{{
    "checklist": {{
        "no_fabrication": 0 or 1,
        "no_distortion": 0 or 1,
        "accurate_extraction": 0 or 1,
        "reasonable_inference": 0 or 1,
        "no_hallucinated_details": 0 or 1
    }},
    "score": <float 0-1, average of checklist>,
    "hallucinations": ["list of specific hallucinations found, if any"]
}}
