You are evaluating the specificity and quality of coaching_hints in the 1on1 meeting prep analysis phase. Coaching hints must be surgically specific, not generic or speculative.

## Input (Q&A pairs + survey data):
{input}

## AI's Output (question_context with coaching_hints):
{output}

## Evaluation Instructions
Focus on the coaching_hint field in each question_context item. Evaluate whether hints are grounded in specific behavioral units and entities from the member's actual responses.

## Checklist - Score each item (0 or 1):

1. **Behavioral Unit Reference**: Does every coaching_hint mention a specific behavioral unit or entity (e.g., "protocol design", "scheduling coordination", "reference analysis for [Name]") from the member's text, rather than generic advice?
2. **No Generic Encouragement**: Are hints free from congratulatory or encouragement patterns ("칭찬해주세요", "격려해주세요", "Congratulate them") and instead focus on "ask about the logic behind [X]" or "explore scaling of [Y]"?
3. **Past-to-Future Bridge**: Does each hint connect a past fact (what happened) to a future support action (what the leader can do next), rather than just restating what the member said?
4. **No Groundless Speculation**: Are hints free from speculative statements about the member's feelings or situations that are not explicitly stated in the input?
5. **Role Attribution Clarity**: When collaboration is mentioned, does the hint clearly distinguish the member's role (direction, decision) from collaborators' roles (execution, implementation)?

## Response Format (JSON):
{{
    "checklist": {{
        "behavioral_unit_reference": 0 or 1,
        "no_generic_encouragement": 0 or 1,
        "past_to_future_bridge": 0 or 1,
        "no_groundless_speculation": 0 or 1,
        "role_attribution_clarity": 0 or 1
    }},
    "score": <float 0-1, average of checklist>,
    "reasoning": "brief explanation with specific examples"
}}
